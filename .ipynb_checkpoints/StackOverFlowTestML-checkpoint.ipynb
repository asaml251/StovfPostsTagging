{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet 6 : Catégorisez automatiquement des questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 2: Modélisation supervisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction qui récupère les features d'un corpus selon une fraction des données entre min_features_to_stop et max_features_to_stop\n",
    "<u>Exemple</u>: get_stop_words(freq_features, 0.2, 0.7) récupère 20 % des features les - significatives et 30% de celles les + significatives, le paramètre freq_features correspond à un vecteur de fréquence des features obtenu avec un modèle CountVectorizer ou TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stop_words(freq_features, min_features_to_stop=0.1, max_features_to_stop=1):\n",
    "    freq_quantile = freq_features.quantile([min_features_to_stop, max_features_to_stop]) \n",
    "    stop_words =list(freq_features[(freq_features < freq_quantile.iloc[0]) | (freq_features > freq_quantile.iloc[1])].index)\n",
    "    return stop_words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retourne un vectorizer (Count/Tfidf) entrainé sur un dataset X_train en précisant le %tage des features à supprimer du vocabulaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_vectorizer_on(vectorizer, X_train, min_features_to_stop=0.1, max_features_to_stop=1):\n",
    "    # Numérisation du texte des posts (Body uniquement) avec TfidfVectorizer\n",
    "    X_features = vectorizer.fit_transform(X_train).toarray()\n",
    "\n",
    "    freq_features = pd.Series(np.sum(X_features, axis=0), index=vectorizer.get_feature_names())\n",
    "\n",
    "    # On élague les features les plus faibles en terme de tf-idf (ou les plus fortes si max_features_to_stop < 1)\n",
    "    stop_words = get_stop_words(freq_features, min_features_to_stop, max_features_to_stop)\n",
    "\n",
    "    # Et renumérisation des posts en tenant compte des stop words calculés\n",
    "    vectorizer.set_params(stop_words=stop_words)\n",
    "    \n",
    "    vectorizer.fit_transform(X_train)\n",
    "\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraine un modèle Naive Bayes sur (X_train, y_train) et calcule l'accuracy score obtenu sur (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def get_score_nbayes_on(nbayes, vectorizer, X_train, y_train, X_test, y_test):\n",
    "    X_train_vect = vectorizer.fit_transform(X_train).toarray()\n",
    "\n",
    "    nbayes.fit(X_train_vect, y_train)\n",
    "\n",
    "    X_test_vect = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "    y_pred = nbayes.predict(X_test_vect)\n",
    "\n",
    "    return metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions de tracé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction de tracé d'un barplot pour une Series\n",
    "def trace_barplot(y, title, kind='bar'):\n",
    "    if (kind=='bar'):\n",
    "        plt.xticks(range(len(y)), list(y.index),rotation = 0, fontsize=14)\n",
    "        plt.bar(range(len(y)),y,width = 0.2, color='red')   \n",
    "    elif (kind=='barh'):       \n",
    "        plt.yticks(range(len(y)), list(y.index),rotation = 0, fontsize=14)\n",
    "        plt.barh(range(len(y)),y,height = 0.2, color='red')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction de tracé d'un histogramme pour un array/Series\n",
    "def trace_hist(y,title,xlabel,ylabel, n_bins):\n",
    "    plt.hist(y, range=(y.min(), y.max()), bins=n_bins,color='yellow',edgecolor='red')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de modèles supervisés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas d'une classification multi-classes, 1 output. \n",
    "#### Test du classifieur sur un jeu de données de posts STOVF taggués avec <u> 1 seul tag </u>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modèle classifieur Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On charge les posts STOVF traités dans le notebook StackoverflowData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stovf_data = pd.read_pickle('C:\\\\Formation\\\\Data scientist\\\\Projet_6\\\\datasets_2\\\\stovfset_4ml.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition du nombre de tags dans le jeu de données\n",
    "# On dispose de 25838 documents avec 1 seul tag\n",
    "stovf_data.Nb_tags.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "stovf_data_one_tag = stovf_data[stovf_data.Nb_tags==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stovf_data_one_tag.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On cleane les tags avec une fréquence très faible: nécessité d'avoir suffisamment de données pour entrainer les modèles sur chacune des classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_freq = stovf_data_one_tag.Tags_cleaned_2.value_counts()\n",
    "print('Nbre de tags avec une fréquence très faible = 1 %*taille des données:', len(tags_freq[tags_freq < 0.01*stovf_data_one_tag.shape[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_to_remove = list(tags_freq[tags_freq < 0.01*stovf_data_one_tag.shape[0]].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des tags non significatifs (représentés par moins de 1% des données)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stovf_data_one_tag.Tags_cleaned_2 = stovf_data_one_tag.Tags_cleaned_2.apply(lambda x: np.nan if x in tags_to_remove else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stovf_data_one_tag.drop(stovf_data_one_tag[stovf_data_one_tag.Tags_cleaned_2.isnull()].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Données d'entrainement et de test avec:\n",
    "X = texte + titre du post STOVF, y = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = stovf_data_one_tag[['Body_cleaned','Title_cleaned']]\n",
    "y = stovf_data_one_tag.Tags_cleaned_2\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des étiquettes finales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "trace_barplot(y.value_counts(), 'Tags et distribution', kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numérisation des posts (Body uniquement) avec CountfVectorizer et application d'un modèle Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "count_vect_body = CountVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "\n",
    "count_vect_body = fit_vectorizer_on(count_vect_body, X_train.Body_cleaned, min_features_to_stop=0.4)\n",
    "\n",
    "print('Taille du vocabulaire:%i' % len(count_vect_body.get_feature_names()))\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nbayes = MultinomialNB()\n",
    "\n",
    "score = get_score_nbayes_on(nbayes, count_vect_body, X_train.Body_cleaned, y_train, X_test.Body_cleaned, y_test)\n",
    "\n",
    "print('Accuracy score - CountVectorizer(Body) + Naive Bayes:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numérisation des posts (Body uniquement) avec TfidffVectorizer et application d'un modèle Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "count_vect_body = TfidfVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "\n",
    "count_vect_body = fit_vectorizer_on(count_vect_body, X_train.Body_cleaned, min_features_to_stop=0.4)\n",
    "\n",
    "print('Taille du vocabulaire:%i' % len(count_vect_body.get_feature_names()))\n",
    "print(' [Min, Max] Tf-idf: [%.2f, %2f]' % (count_vect_body.idf_.min(),count_vect_body.idf_.max()) )\n",
    "\n",
    "nbayes = MultinomialNB()\n",
    "\n",
    "score = get_score_nbayes_on(nbayes, count_vect_body, X_train.Body_cleaned, y_train, X_test.Body_cleaned, y_test)\n",
    "\n",
    "print('Accuracy score - TfidfVectorizer(Body) + Naive Bayes:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numérisation des posts (Title uniquement) avec CountVectorizer et application d'un modèle Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "\n",
    "count_vect = fit_vectorizer_on(count_vect, X_train.Title_cleaned, min_features_to_stop=0.4)\n",
    "\n",
    "print('Taille du vocabulaire:%i' % len(count_vect.get_feature_names()))\n",
    "\n",
    "nbayes = MultinomialNB()\n",
    "\n",
    "score = get_score_nbayes_on(nbayes, count_vect, X_train.Title_cleaned, y_train, X_test.Title_cleaned, y_test)\n",
    "\n",
    "print('Accuracy score - CountVectorizer(Title) + Naive Bayes:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numérisation des posts (Title uniquement) avec TfidffVectorizer et application d'un modèle Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = TfidfVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "\n",
    "count_vect = fit_vectorizer_on(count_vect, X_train.Title_cleaned, min_features_to_stop=0.4)\n",
    "\n",
    "print('Taille du vocabulaire:%i' % len(count_vect.get_feature_names()))\n",
    "print(' [Min, Max] Tf-idf: [%.2f, %2f]' % (count_vect.idf_.min(),count_vect.idf_.max()) )\n",
    "\n",
    "nbayes = MultinomialNB()\n",
    "\n",
    "score = get_score_nbayes_on(nbayes, count_vect, X_train.Title_cleaned, y_train, X_test.Title_cleaned, y_test)\n",
    "\n",
    "print('Accuracy score - TfidfVectorizer(Title) + Naive Bayes:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numérisation des posts (Body+Title séparément) avec CountVectorizer et application d'un modèle Naive Bayes sur la concaténation des features Body  + features Title \n",
    "-> on considère 2 contextes différents suivant que le mot appartienne au post ou au titre du post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_body = CountVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "count_vect_body = fit_vectorizer_on(count_vect_body, X_train.Body_cleaned, min_features_to_stop=0.4)\n",
    "X_train_vect_body = count_vect_body.fit_transform(X_train.Body_cleaned).toarray()\n",
    "\n",
    "count_vect_title = CountVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "count_vect_title = fit_vectorizer_on(count_vect_title, X_train.Title_cleaned, min_features_to_stop=0.4)\n",
    "X_train_vect_title = count_vect_title.fit_transform(X_train.Title_cleaned).toarray()\n",
    "\n",
    "nbayes = MultinomialNB()\n",
    "\n",
    "X_train_vect_body_title = np.concatenate((X_train_vect_body, X_train_vect_title), axis=1)\n",
    "\n",
    "nbayes.fit(X_train_vect_body_title, y_train)\n",
    "\n",
    "X_test_vect_body = count_vect_body.transform(X_test.Body_cleaned).toarray()\n",
    "X_test_vect_title = count_vect_title.transform(X_test.Title_cleaned).toarray()\n",
    "\n",
    "X_test_vect_body_title = np.concatenate((X_test_vect_body, X_test_vect_title), axis=1)\n",
    "\n",
    "y_pred = nbayes.predict(X_test_vect_body_title)\n",
    "\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Accuracy score - CountVectorizer(Body+Title) + Naive Bayes:', score)\n",
    "nbayes.score(X_test_vect_body_title, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On visualise les résultats des prédictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sur un échantillon aléatoire de 5 posts\n",
    "pd.DataFrame({'Body':X_test.Body_cleaned,'Title':X_test.Title_cleaned,'y_test':y_test,'y_pred':y_pred}).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modèle classifieur Régression logistique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numérisation des posts (Body uniquement) avec TfidffVectorizer et application d'un modèle de Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression(multi_class='ovr')\n",
    "\n",
    "# Body vectorization (Train)\n",
    "count_vect_body = TfidfVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "count_vect_body = fit_vectorizer_on(count_vect_body, X_train.Body_cleaned, min_features_to_stop=0.4)\n",
    "X_train_vect_body = count_vect_body.fit_transform(X_train.Body_cleaned).toarray()\n",
    "\n",
    "logreg.fit(X_train_vect_body, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul des probabilités d'appartenance à chacune des classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Body vectorization (Test)\n",
    "X_test_vect_body = count_vect_body.transform(X_test.Body_cleaned).toarray()\n",
    "\n",
    "# On récupère la prédiction de la valeur positive\n",
    "y_prob = logreg.predict_proba(X_test_vect_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mesure intuitive de l'efficacité de chacun des classifieurs en regardant le nombre de points autour de la frontière de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_posts_near_decisionf=[]\n",
    "for i in range(y_prob.shape[1]):\n",
    "    nb_points = sum((y_prob[:,i]  > 0.4) & (y_prob[:,i]  < 0.6))\n",
    "    nb_posts_near_decisionf.append(nb_points*100/y_prob.shape[0])\n",
    "nb_posts_near_decisionf\n",
    "#pd.DataFrame({'Pourcentage de posts autour de la frontière de décision (proba. entre 0.4 et 0.6)':nb_posts_near_decisionf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logreg.score(X_test_vect_body, y_test)\n",
    "\n",
    "print('Accuracy score - TfidfVectorizer(Body) + Logistic Regression:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numérisation des posts (Body + Title) avec TfidffVectorizer et application d'un modèle de Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(multi_class='ovr')\n",
    "\n",
    "# Title vectorization (Train)\n",
    "count_vect_title = TfidfVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "count_vect_title = fit_vectorizer_on(count_vect_title, X_train.Title_cleaned, min_features_to_stop=0.4)\n",
    "X_train_vect_title = count_vect_title.fit_transform(X_train.Title_cleaned).toarray()\n",
    "\n",
    "# Body + Title concatenation (Train)\n",
    "X_train_vect_body_title = np.concatenate((X_train_vect_body, X_train_vect_title), axis=1)\n",
    "\n",
    "logreg.fit(X_train_vect_body_title, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title vectorization (Test)\n",
    "X_test_vect_title = count_vect_title.transform(X_test.Title_cleaned).toarray()\n",
    "# Body + Title concatenation (Test)\n",
    "X_test_vect_body_title = np.concatenate((X_test_vect_body, X_test_vect_title), axis=1) \n",
    "\n",
    "score = logreg.score(X_test_vect_body_title, y_test)\n",
    "\n",
    "print('Accuracy score - TfidfVectorizer(Body + Title) + Logistic Regression:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation croisée sur le modèle de régression logistique (Body+Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = linear_model.LogisticRegression(multi_class='ovr')\n",
    " \n",
    "scores = cross_val_score(clf, X_train_vect_body_title, y_train, cv=5)\n",
    "print('Moyenne des erreurs du modèle :', scores.mean())\n",
    "print('Variance des erreurs du modèle :', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation croisée avec recherche du meilleur modèle sur les hyperparamètres {C, penalty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "\n",
    "param_grid = {'C':10.0**-np.arange(-2,2),\n",
    "              'penalty': ['l1','l2']\n",
    "             }\n",
    "score = 'accuracy'\n",
    "\n",
    "clf = model_selection.GridSearchCV(\n",
    "    linear_model.LogisticRegression(multi_class='ovr'), \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring=score \n",
    ")\n",
    "\n",
    "clf.fit(X_train_vect_body_title, y_train)\n",
    "\n",
    "print (\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\", clf.best_params_)\n",
    "\n",
    "print (\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], clf.cv_results_['std_test_score'], clf.cv_results_['params']):\n",
    "    print (\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (score, mean, std*2,params ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le meilleur score de 69,4 % est obtenu avec C = 1 et penalty = l1 (méthode Lasso) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test_vect_body_title, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement d'un SGD Classifier avec les paramètres sklearn par défaut \n",
    "et en considérant la fonction de coût d'une Régression logistique (paramètre loss='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# ici pas nécessaire de scaler les features avant entrainement\n",
    "sgd = SGDClassifier(loss=\"log\")\n",
    "sgd.fit(X_train_vect_body_title, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = sgd.score(X_test_vect_body_title, y_test)\n",
    "\n",
    "print('Accuracy score - TfidfVectorizer(Body + Title) + SGD Classifieur:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation croisée et recherche du meilleur modèle avec une GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "\n",
    "param_grid = {#'alpha': 10.0**-np.arange(1,7),\n",
    "              'alpha': [5e-06,8e-06,1e-05,5e-05,9e-05],\n",
    "              'penalty': ['l1','l2','elasticnet']              \n",
    "             }\n",
    "\n",
    "score = 'accuracy'\n",
    "\n",
    "clf = model_selection.GridSearchCV(\n",
    "    linear_model.SGDClassifier(loss=\"log\"), \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring=score \n",
    ")\n",
    "\n",
    "clf.fit(X_train_vect_body_title, y_train)\n",
    "\n",
    "print (\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\", clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], clf.cv_results_['std_test_score'], clf.cv_results_['params']):\n",
    "    print (\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (score, mean, std*2,params ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.score(X_test_vect_body_title, y_test)\n",
    "\n",
    "print('Accuracy score - TfidfVectorizer(Body + Title) + SGD Classifieur:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On peut agréger les résultats des 3 classifieurs précédents avec un VotingClassifier pour un vote à la majorité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = MultinomialNB()\n",
    "clf2 = linear_model.LogisticRegression(multi_class='ovr', random_state=1) \n",
    "clf3 = linear_model.SGDClassifier(loss=\"log\", alpha=9e-05, penalty='l1', random_state=1, max_iter=10)\n",
    "\n",
    "vclf = VotingClassifier(estimators=[('mnb', clf1), ('lr', clf2), ('sgd', clf3)], voting='hard')\n",
    "\n",
    "# on fait une validation croisée \n",
    "for clf, label in zip([clf1, clf2, clf3, vclf], ['Naive Bayes', 'Logistic Regression', 'SGD', 'Ensemble']):\n",
    "     scores = cross_val_score(clf, X_train_vect_body_title, y_train, cv=5, scoring='accuracy')\n",
    "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Conclusion</u>: le VotingClassifier n'a pas permis d'améliorer les résultats de chacun des 3 classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = vclf.score(X_test_vect_body_title, y_test)\n",
    "print('Accuracy score - TfidfVectorizer(Body + Title) + VotingClassifier:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas d'une classification multi-classes, multi-output. \n",
    "#### Test du classifieur sur un jeu de données de posts STOVF taggués avec 1 ou plusieurs tags \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modèle classifieur Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation des données d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = stovf_data[['Body_cleaned','Title_cleaned']]\n",
    "y = stovf_data.Tags_cleaned_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiLabelBinarizer sur les tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y_mlb= mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On reconstruit un dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mlb = pd.DataFrame(y_mlb, columns=mlb.classes_, index=y.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comme pour le traitement des posts à 1 seul tag, on supprime les tags qui apparaissent dans moins de 1% de la taille du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_posts_per_tag = y_mlb.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_to_remove = nb_posts_per_tag[nb_posts_per_tag < 0.05*X.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbre initial de tags: 6555\n",
      "Nbre de tags à supprimer: 6549\n"
     ]
    }
   ],
   "source": [
    "print('Nbre initial de tags: %i' % y_mlb.shape[1])\n",
    "print('Nbre de tags à supprimer: %i' % len(tags_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Suppression des colonnes tags\n",
    "y_mlb.drop(list(tags_to_remove.index), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59239, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimension de y_mlb\n",
    "y_mlb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.net</th>\n",
       "      <th>asp.net</th>\n",
       "      <th>c#</th>\n",
       "      <th>c++</th>\n",
       "      <th>java</th>\n",
       "      <th>javascript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   .net  asp.net  c#  c++  java  javascript\n",
       "0     0        0   1    0     0           0\n",
       "1     0        0   0    0     0           0\n",
       "2     1        0   1    0     0           0\n",
       "4     0        0   0    0     0           1\n",
       "5     1        0   0    0     0           0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la matrice apparait moins \"creuse\" (sparse)\n",
    "y_mlb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trace_barplot(nb_posts_per_tag, 'Tags et distribution', kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".net          6219\n",
       "asp.net       3946\n",
       "c#            9526\n",
       "c++           3540\n",
       "java          5056\n",
       "javascript    3237\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nbre de documents par tag\n",
    "y_mlb.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation du jeu d'entrainement et de test \n",
    "On se limite là aussi à un dataset de 20000 posts pour des pbs de capacité mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X[['Body_cleaned','Title_cleaned']][:20000] , y_mlb[:20000], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On extrait les features selon les mêmes règles que précédemment avec un CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_body = CountVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "count_vect_body = fit_vectorizer_on(count_vect_body, X_train.Body_cleaned, min_features_to_stop=0.4)\n",
    "X_train_vect_body = count_vect_body.fit_transform(X_train.Body_cleaned).toarray()\n",
    "\n",
    "count_vect_title = CountVectorizer(ngram_range=(1,2), min_df=20, max_df=0.15)\n",
    "count_vect_title = fit_vectorizer_on(count_vect_title, X_train.Title_cleaned, min_features_to_stop=0.4)\n",
    "X_train_vect_title = count_vect_title.fit_transform(X_train.Title_cleaned).toarray()\n",
    "\n",
    "X_train_vect_body_title = np.concatenate((X_train_vect_body, X_train_vect_title), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_vect_body = count_vect_body.transform(X_test.Body_cleaned).toarray()\n",
    "X_test_vect_title = count_vect_title.transform(X_test.Title_cleaned).toarray()\n",
    "\n",
    "X_test_vect_body_title = np.concatenate((X_test_vect_body, X_test_vect_title), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiOutputClassifier & Naive Bayes\n",
    "On entraine n classifieurs Naive Bayes binaires de manière indépendante avec n = nbre de tags (44 outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "nbayes = MultinomialNB()\n",
    "\n",
    "multi_target_nbayes = MultiOutputClassifier(nbayes, n_jobs=-1)\n",
    "multi_target_nbayes.fit(X_train_vect_body_title, y_train)                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multi_target_nbayes.predict(X_test_vect_body_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "\n",
    "print('Accuracy score: % .2f' % metrics.accuracy_score(y_pred, y_test))\n",
    "print('Hamming loss score: % .2f' % metrics.hamming_loss(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = multi_target_nbayes.predict(X_test_vect_body_title[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit_transform([['titi', 'sci-fi', 'thriller'], ['thriller','toto','sci-fi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss,accuracy_score,f1_score\n",
    "hamming_loss(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[0,0,0],\n",
    "                   [0,1,1],\n",
    "                   [1,1,1],\n",
    "                   [0,0,1]])\n",
    "\n",
    "y_pred = np.array([[0,1,1],\n",
    "                   [0,1,1],\n",
    "                   [0,1,0],\n",
    "                   [0,0,1]])\n",
    "hamming_loss(y_true,y_pred)\n",
    "#metrics.accuracy_score(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_score(y_true,y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
